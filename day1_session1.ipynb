{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "oX7spwWZiGfH",
        "dJ4PdLLq4qqj",
        "x-HKLQfsJ8Fy",
        "IPcBM7DTnM4D"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abeebyekeen/DLforBeginners/blob/main/day1_session1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#day 1 session 1: introduction to binary classification\n",
        "\n",
        "**scenario**: binary classification ($y \\in \\{1,0\\}$) <br>\n",
        "**dataset**: almost linearly separable dataset #1 in 2-d ($\\mathbf{x^i} = [x_0^i,x_1^i]$) <br>\n",
        "**model**: linear classifier (1-layer perceptron):\n",
        "   $$ y=   \\left\\{\n",
        "\\begin{array}{ll}\n",
        "      1 & w_0 x_0 + w_1 x_1 + b > 0 \\\\\n",
        "      0 & w_0 x_0 + w_1 x_1 + b \\leq 0 \\\\\n",
        "\\end{array}\n",
        "\\right.  $$<br>\n",
        "\n",
        "\n",
        "**tasks** <br>\n",
        "1. draw (on paper) the plot of $h = w_0 x_0 + w_1 x_1 + b$, where $x_0$ and $x_1$ are variables and $w_0$, $w_1$, $b$ are parameters\n",
        "\n",
        "2. visualize dataset #1; guess the best value of parameters of the linear classifier; guess the rates of TN, FP, FN, TP and ACC <br>\n",
        "\n",
        "3. implement the linear classifier (without bias (why?)) to maximize ACC, train and infer<br>\n",
        "\n",
        "4. rewrite dataset #1 (move all points top-right by 0.25 and 0.25); repeat task 3; if performance is poor come up with a way to improve it\n",
        "\n",
        "5. rewrite dataset #1 so that the number of data points from class 0 is 7 times as many as those from class 1; repeat task 3; if performance is poor come up with a way to improve it\n",
        "\n",
        "6. rewrite objective function to improve Precision ( $\\frac{TP}{TP+FP}$ ), Recall or Sensitivity ($\\frac{TP}{TP+FN}$), and Specificity or Selectivity ($\\frac{TN}{TN+FP}$); repeat task 3 and see what happens to accuracy\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "opZfIzlO8Xty"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##part 0: dependencies and functions\n",
        "utility code that you don't have to read"
      ],
      "metadata": {
        "id": "oX7spwWZiGfH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mq1r6g4Zdq9B"
      },
      "outputs": [],
      "source": [
        "# dependencies\n",
        "import numpy as np\n",
        "import math\n",
        "import scipy\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from IPython.display import Javascript"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function for visualizing dataset\n",
        "def visualize_data(X,Y,figuretitle):\n",
        "    fig = plt.figure()\n",
        "    ax = plt.gca()\n",
        "    C0 = ax.scatter(X[Y==0,0],X[Y==0,1],c='b')\n",
        "    C1 = ax.scatter(X[Y==1,0],X[Y==1,1],c='r')\n",
        "    #c = ['b' if Y[i]==0 else 'r' for i in range(len(Y))]\n",
        "    #scatter = ax.scatter(X[:,0], X[:,1], c=c)\n",
        "    ax.set_aspect('equal')\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(base=0.2))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(base=0.2))\n",
        "    legend1 = ax.legend((C0,C1),('y=0','y=1'),loc='upper left',)\n",
        "    plt.xlabel('x0')\n",
        "    plt.ylabel('x1')\n",
        "    plt.title(figuretitle)\n",
        "    plt.plot()"
      ],
      "metadata": {
        "id": "YA-_Nbgux-83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function for visualizing loss function\n",
        "def visualize_loss(Jout, w0_start, w0_end, w1_start, w1_end, step):\n",
        "    x = np.arange(w0_start - 0.5*step, w0_end + 1.0*step, step)\n",
        "    y = np.arange(w1_start - 0.5*step, w1_end + 1.0*step, step)\n",
        "    z = Jout\n",
        "    fig, ax = plt.subplots()\n",
        "    c = ax.pcolormesh(x, y, z)\n",
        "    ax.set_aspect('equal')\n",
        "    ax.set_xticks(x[:-1]+0.5*step)\n",
        "    ax.set_yticks(y[:-1]+0.5*step)\n",
        "    fig.colorbar(c, ax=ax)"
      ],
      "metadata": {
        "id": "z6F1gkNwj-RX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#modified from a piece of code from erwan-simon: \"https://gist.github.com/erwan-simon/e3baef06a00bb9a39a6968acf78121ee\"\n",
        "#from torch.autograd import Variable\n",
        "def plot_decision_boundary(X,Y,w,model):\n",
        "    dataset= X\n",
        "    labels = Y\n",
        "    color_map='Paired'\n",
        "    color_map = plt.get_cmap(color_map)\n",
        "    # Define region of interest by data limits\n",
        "    x0min, x0max = dataset[:, 0].min() - 1, dataset[:, 0].max() + 1\n",
        "    x1min, x1max = dataset[:, 1].min() - 1, dataset[:, 1].max() + 1\n",
        "    steps = 1000\n",
        "    x0_span = np.linspace(x0min, x0max, steps)\n",
        "    x1_span = np.linspace(x1min, x1max, steps)\n",
        "    x0s, x1s = np.meshgrid(x0_span, x1_span)\n",
        "\n",
        "    # Make predictions across region of interest\n",
        "    #model.eval()\n",
        "    #labels_predicted = model(Variable(torch.from_numpy(np.c_[xx.ravel(), yy.ravel()]).float()))\n",
        "    labels_predicted = model(w, np.c_[x0s.ravel(), x1s.ravel()])\n",
        "    # Plot decision boundary in region of interest\n",
        "    #labels_predicted = [0 if value <= 0.5 else 1 for value in labels_predicted.detach().numpy()]\n",
        "    z = np.array(labels_predicted).reshape(x0s.shape)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    contourf_ = ax.contourf(x0s, x1s, z, cmap=color_map, alpha=0.5)\n",
        "    cbar = fig.colorbar(contourf_)\n",
        "    #cbar.set_clim( vmin, vmax )\n",
        "\n",
        "    # Get predicted labels on training data and plot\n",
        "    #train_labels_predicted = model(dataset)\n",
        "\n",
        "    C0 = ax.scatter(X[Y==0,0],X[Y==0,1],c='b')\n",
        "    C1 = ax.scatter(X[Y==1,0],X[Y==1,1],c='r')\n",
        "    ax.set_aspect('equal')\n",
        "    #ax.set(xlim=(-3, 3), ylim=(-3, 3))\n",
        "    plt.xlabel('x0')\n",
        "    plt.ylabel('x1')\n",
        "    plt.title(\"infering data, true labels, decision bounary\")\n",
        "    plt.plot()"
      ],
      "metadata": {
        "id": "MjuPGn9096wY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print the rates of TN, FP, FN, TP, and ACC\n",
        "def evaluate(Y,Y_pred):\n",
        "    total = len(Y)\n",
        "    TN = np.count_nonzero(np.logical_and(Y==0.0,Y_pred==0.0)) / total\n",
        "    FP = np.count_nonzero(np.logical_and(Y==0.0,Y_pred==1.0)) / total\n",
        "    FN = np.count_nonzero(np.logical_and(Y==1.0,Y_pred==0.0)) / total\n",
        "    TP = np.count_nonzero(np.logical_and(Y==1.0,Y_pred==1.0)) / total\n",
        "    ACC = TN+TP\n",
        "    print('TN rate:',TN,', FP rate: ',FP,', FN rate: ',FN,', TP rate: ',TP)\n",
        "    print('ACC=',ACC)"
      ],
      "metadata": {
        "id": "SDEsWXoudL9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##part 1: preparations"
      ],
      "metadata": {
        "id": "dJ4PdLLq4qqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the function that creates dataset #1\n",
        "def create_data_1(N):\n",
        "    X0 = np.random.rand(N,2).astype(np.float32)-0.5\n",
        "    X1 = np.random.rand(N,2).astype(np.float32)-0.5\n",
        "    X0[:,0] = X0[:,0] - 0.25\n",
        "    X1[:,0] = X1[:,0] + 0.25\n",
        "    X0[:,1] = X0[:,1] - 0.25\n",
        "    X1[:,1] = X1[:,1] + 0.25\n",
        "    X = np.concatenate((X0,X1), axis=0)\n",
        "    Y0 = np.zeros((N)).astype(np.float32)\n",
        "    Y1 = np.ones( (N)).astype(np.float32)\n",
        "    Y = np.concatenate((Y0,Y1), axis=0)\n",
        "    new_id = np.random.permutation(2*N)\n",
        "    X = X[new_id]\n",
        "    Y = Y[new_id]\n",
        "    return X,Y"
      ],
      "metadata": {
        "id": "Io3m1aQ5x-iw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# call the function above to actually create dataset #1\n",
        "SEED = 2023\n",
        "np.random.seed(SEED)\n",
        "N=5000\n",
        "X,Y=create_data_1(N)\n",
        "X_train = X[:N]\n",
        "Y_train = Y[:N]\n",
        "X_infer = X[N:]\n",
        "Y_infer = Y[N:]\n",
        "\n",
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 9999})'''))\n",
        "visualize_data(X,Y,\"dataset\")\n",
        "visualize_data(X_train,Y_train,\"dataset train\")\n",
        "visualize_data(X_infer,Y_infer,\"dataset infer\")"
      ],
      "metadata": {
        "id": "ukdGDh-GWcXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build a linear classifier model\n",
        "def MyLinearClassifier(w, x):\n",
        "    y = None # edit here\n",
        "    return y"
      ],
      "metadata": {
        "id": "2Gv29lciD7zD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# formulate performance evaluation function\n",
        "def MyErrorRate(w,x,y):\n",
        "    y_pred = MyLinearClassifier(w, x)\n",
        "    diff = np.logical_xor(y, y_pred)\n",
        "    error_rate = diff.sum() / len(diff)\n",
        "    return error_rate"
      ],
      "metadata": {
        "id": "LMcf0Xp0lwQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## part 2: train"
      ],
      "metadata": {
        "id": "x-HKLQfsJ8Fy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# here we look for the best parameters for our model\n",
        "w0_start, w0_end, w1_start, w1_end, step = -4, 4, -4, 4, 1.0\n",
        "rranges = (slice(w0_start, w0_end+step, step), slice(w1_start, w1_end+step, step))\n",
        "w_opt, fval, grid, Jout = scipy.optimize.brute(MyErrorRate, ranges=rranges, args=(X_train, Y_train), full_output=True, finish=None, disp=False, workers=1)\n",
        "print(w_opt)\n",
        "print(fval)\n",
        "print(grid)\n",
        "print(Jout)"
      ],
      "metadata": {
        "id": "8Rt_Dh2oSV_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# here we plot the\n",
        "visualize_loss(Jout, w0_start,w0_end,w1_start,w1_end,step)"
      ],
      "metadata": {
        "id": "8h6gSMhbgYKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## part 3: infer"
      ],
      "metadata": {
        "id": "IPcBM7DTnM4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use the model with the best parameters to classify dataset we left aside\n",
        "Y_infer_pred = MyLinearClassifier(w_opt, X_infer)"
      ],
      "metadata": {
        "id": "43Yhh18-SW9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the classification performance with most basic metrics\n",
        "evaluate(Y_infer,Y_infer_pred)"
      ],
      "metadata": {
        "id": "4lY5QF4ESabx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the decision boundary together with the infer dataset\n",
        "plot_decision_boundary(X_infer,Y_infer_pred,w_opt,MyLinearClassifier)"
      ],
      "metadata": {
        "id": "i6TThgS85Cie"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
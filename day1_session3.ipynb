{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "oX7spwWZiGfH"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abeebyekeen/DLforBeginners/blob/main/day1_session3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#day 1 session 3: visualization of loss surface and optimization\n",
        "\n",
        "Downhill Simplex Optimization (or Nelderâ€“Mead method [wiki](https://en.wikipedia.org/wiki/Nelder%E2%80%93Mead_method) [scipy](https://docs.scipy.org/doc/scipy/reference/optimize.minimize-neldermead.html)) in 2D parameter space\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "opZfIzlO8Xty"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**tasks**:\n",
        "1. implement the perceptron model and BCE loss function\n",
        "2. run the pipeline and observe how Downhill Simplex Optimization works\n",
        "3. to view its behavior near the minimum more clearly with higher contrast, plot only the area around the minimum\n",
        "4. use Downhill Simplex Optimization on task 2 from session 2\n",
        "5. use Downhill Simplex Optimization on task 3 from session 2\n",
        "6. use Downhill Simplex Optimization on task 4 from session 2\n",
        "7. apply Downhill Simplex Optimization on multiclass classification problem (create your own dataset, perceptron, loss)"
      ],
      "metadata": {
        "id": "UJOAUf4HtUUp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##part 0: dependencies and functions\n",
        "utility code that you don't have to read"
      ],
      "metadata": {
        "id": "oX7spwWZiGfH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mq1r6g4Zdq9B"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from IPython.display import Javascript"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function for creating a binary classification dataset\n",
        "def create_data_1(N):\n",
        "    X0 = np.random.rand(N,2).astype(np.float32)-0.5\n",
        "    X1 = np.random.rand(N,2).astype(np.float32)-0.5\n",
        "    X0[:,0] = X0[:,0] - 0.25\n",
        "    X1[:,0] = X1[:,0] + 0.25\n",
        "    X0[:,1] = X0[:,1] - 0.25\n",
        "    X1[:,1] = X1[:,1] + 0.25\n",
        "    X = np.concatenate((X0,X1), axis=0)\n",
        "    Y0 = np.zeros((N)).astype(np.float32)\n",
        "    Y1 = np.ones( (N)).astype(np.float32)\n",
        "    Y = np.concatenate((Y0,Y1), axis=0)\n",
        "    # shuffle X and Y\n",
        "    new_id = np.random.permutation(2*N)\n",
        "    X = X[new_id]\n",
        "    Y = Y[new_id]\n",
        "    return X,Y"
      ],
      "metadata": {
        "id": "Io3m1aQ5x-iw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function for creating a binary classification dataset\n",
        "def create_data_2(N):\n",
        "    r0 = np.random.rand(N).astype(np.float32)+1.0\n",
        "    r1 = np.random.rand(N).astype(np.float32)+3.0\n",
        "    theta0 = (np.random.rand(N)-0.5).astype(np.float32) * 2.0 * np.pi\n",
        "    theta1 = (np.random.rand(N)-0.5).astype(np.float32) * 2.0 * np.pi\n",
        "    X0 = np.column_stack((r0*np.cos(theta0),r0*np.sin(theta0)))\n",
        "    X1 = np.column_stack((r1*np.cos(theta1),r1*np.sin(theta1)))\n",
        "    X = np.concatenate((X0,X1), axis=0)\n",
        "    Y0 = np.zeros((N)).astype(np.float32)\n",
        "    Y1 = np.ones( (N)).astype(np.float32)\n",
        "    Y = np.concatenate((Y0,Y1))\n",
        "    # shuffle X and Y\n",
        "    new_id = np.random.permutation(2*N)\n",
        "    X = X[new_id]\n",
        "    Y = Y[new_id]\n",
        "    return X,Y"
      ],
      "metadata": {
        "id": "cg1ZsahyO97U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function for creating a binary classification dataset\n",
        "def create_data_3(N):\n",
        "    X1 = np.random.rand(N,2).astype(np.float32)\n",
        "    X2 = np.random.rand(N,2).astype(np.float32)\n",
        "    X3 = np.random.rand(N,2).astype(np.float32)\n",
        "    X4 = np.random.rand(N,2).astype(np.float32)\n",
        "    X2[:,0] = X2[:,0] - 1.0\n",
        "    X3 = X3 - 1.0\n",
        "    X4[:,1] = X4[:,1] - 1.0\n",
        "    X = np.concatenate((X1,X2,X3,X4), axis=0)\n",
        "    Y1 = np.zeros((N)).astype(np.float32)\n",
        "    Y2 = np.ones( (N)).astype(np.float32)\n",
        "    Y3 = np.zeros((N)).astype(np.float32)\n",
        "    Y4 = np.ones( (N)).astype(np.float32)\n",
        "    Y = np.concatenate((Y1,Y2,Y3,Y4), axis=0)\n",
        "    # shuffle X and Y\n",
        "    new_id = np.random.permutation(4*N)\n",
        "    X = X[new_id]\n",
        "    Y = Y[new_id]\n",
        "    return X,Y"
      ],
      "metadata": {
        "id": "rqi5ngPlO-eN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function for visualizing dataset\n",
        "def visualize_data(X,Y,figuretitle):\n",
        "    fig = plt.figure()\n",
        "    ax = plt.gca()\n",
        "    C0 = ax.scatter(X[Y==0,0],X[Y==0,1],c='b')\n",
        "    C1 = ax.scatter(X[Y==1,0],X[Y==1,1],c='r')\n",
        "    #c = ['b' if Y[i]==0 else 'r' for i in range(len(Y))]\n",
        "    #scatter = ax.scatter(X[:,0], X[:,1], c=c)\n",
        "    ax.set_aspect('equal')\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(base=0.2))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(base=0.2))\n",
        "    legend1 = ax.legend((C0,C1),('y=0','y=1'),loc='upper left',)\n",
        "    plt.xlabel('x0')\n",
        "    plt.ylabel('x1')\n",
        "    plt.title(figuretitle)\n",
        "    plt.plot()"
      ],
      "metadata": {
        "id": "YA-_Nbgux-83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function for visualizing loss function\n",
        "def visualize_loss(Jout, w0_start, w0_end, w1_start, w1_end, step):\n",
        "    x = np.arange(w0_start - 0.5*step, w0_end + 1.0*step, step)\n",
        "    y = np.arange(w1_start - 0.5*step, w1_end + 1.0*step, step)\n",
        "    z = Jout\n",
        "    fig, ax = plt.subplots()\n",
        "    c = ax.pcolormesh(x, y, z)\n",
        "    ax.set_aspect('equal')\n",
        "    ax.set_xticks(x[:-1]+0.5*step)\n",
        "    ax.set_yticks(y[:-1]+0.5*step)\n",
        "    fig.colorbar(c, ax=ax)"
      ],
      "metadata": {
        "id": "N-uT3KbOxDqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#modified from a piece of code from erwan-simon: \"https://gist.github.com/erwan-simon/e3baef06a00bb9a39a6968acf78121ee\"\n",
        "#from torch.autograd import Variable\n",
        "def plot_decision_boundary(X,Y,w,model):\n",
        "    dataset= X\n",
        "    labels = Y\n",
        "    color_map='Paired'\n",
        "    color_map = plt.get_cmap(color_map)\n",
        "    # Define region of interest by data limits\n",
        "    x0min, x0max = dataset[:, 0].min() - 1, dataset[:, 0].max() + 1\n",
        "    x1min, x1max = dataset[:, 1].min() - 1, dataset[:, 1].max() + 1\n",
        "    steps = 1000\n",
        "    x0_span = np.linspace(x0min, x0max, steps)\n",
        "    x1_span = np.linspace(x1min, x1max, steps)\n",
        "    x0s, x1s = np.meshgrid(x0_span, x1_span)\n",
        "\n",
        "    # Make predictions across region of interest\n",
        "    #model.eval()\n",
        "    #labels_predicted = model(Variable(torch.from_numpy(np.c_[xx.ravel(), yy.ravel()]).float()))\n",
        "    labels_predicted = model(w, np.c_[x0s.ravel(), x1s.ravel()])\n",
        "    # Plot decision boundary in region of interest\n",
        "    #labels_predicted = [0 if value <= 0.5 else 1 for value in labels_predicted.detach().numpy()]\n",
        "    z = np.array(labels_predicted).reshape(x0s.shape)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    contourf_ = ax.contourf(x0s, x1s, z, cmap=color_map, alpha=0.5)\n",
        "    cbar = fig.colorbar(contourf_)\n",
        "    #cbar.set_clim( vmin, vmax )\n",
        "\n",
        "    # Get predicted labels on training data and plot\n",
        "    #train_labels_predicted = model(dataset)\n",
        "\n",
        "    C0 = ax.scatter(X[Y==0,0],X[Y==0,1],c='b')\n",
        "    C1 = ax.scatter(X[Y==1,0],X[Y==1,1],c='r')\n",
        "    ax.set_aspect('equal')\n",
        "    #ax.set(xlim=(-3, 3), ylim=(-3, 3))\n",
        "    plt.xlabel('x0')\n",
        "    plt.ylabel('x1')\n",
        "    plt.title(\"infering data, true labels, decision bounary\")\n",
        "    plt.plot()"
      ],
      "metadata": {
        "id": "fVulZqWzxIWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print the rates of TN, FP, FN, TP, and ACC\n",
        "def evaluate(Y,Y_pred):\n",
        "    total = len(Y)\n",
        "    TN = np.count_nonzero(np.logical_and(Y==0.0,Y_pred==0.0)) / total\n",
        "    FP = np.count_nonzero(np.logical_and(Y==0.0,Y_pred==1.0)) / total\n",
        "    FN = np.count_nonzero(np.logical_and(Y==1.0,Y_pred==0.0)) / total\n",
        "    TP = np.count_nonzero(np.logical_and(Y==1.0,Y_pred==1.0)) / total\n",
        "    ACC = TN+TP\n",
        "    print('TN rate:',TN,', FP rate: ',FP,', FN rate: ',FN,', TP rate: ',TP)\n",
        "    print('ACC=',ACC)"
      ],
      "metadata": {
        "id": "KK0f5H4axDJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# modified from\n",
        "# https://github.com/fchollet/nelder-mead/blob/master/nelder_mead.py\n",
        "import copy\n",
        "\n",
        "'''\n",
        "    Pure Python/Numpy implementation of the Nelder-Mead algorithm.\n",
        "    Reference: https://en.wikipedia.org/wiki/Nelder%E2%80%93Mead_method\n",
        "'''\n",
        "\n",
        "\n",
        "def nelder_mead(f, x_start,args,\n",
        "                step=0.1, no_improve_thr=10e-6,\n",
        "                no_improv_break=10, max_iter=0,\n",
        "                alpha=1., gamma=2., rho=-0.5, sigma=0.5):\n",
        "    '''\n",
        "        @param f (function): function to optimize, must return a scalar score\n",
        "            and operate over a numpy array of the same dimensions as x_start\n",
        "        @param x_start (numpy array): initial position\n",
        "        @param step (float): look-around radius in initial step\n",
        "        @no_improv_thr,  no_improv_break (float, int): break after no_improv_break iterations with\n",
        "            an improvement lower than no_improv_thr\n",
        "        @max_iter (int): always break after this number of iterations.\n",
        "            Set it to 0 to loop indefinitely.\n",
        "        @alpha, gamma, rho, sigma (floats): parameters of the algorithm\n",
        "            (see Wikipedia page for reference)\n",
        "\n",
        "        return: tuple (best parameter array, best score)\n",
        "    '''\n",
        "\n",
        "    # init\n",
        "    dim = len(x_start)\n",
        "    prev_best = f(x_start,*args)\n",
        "    no_improv = 0\n",
        "    res = [[x_start, prev_best]]\n",
        "\n",
        "    for i in range(dim):\n",
        "        x = copy.copy(x_start)\n",
        "        x[i] = x[i] + step\n",
        "        score = f(x,*args)\n",
        "        res.append([x, score])\n",
        "\n",
        "    record = []\n",
        "    record.append(copy.deepcopy(res))\n",
        "    # simplex iter\n",
        "    iters = 0\n",
        "    while 1:\n",
        "        print()\n",
        "        # order\n",
        "        res.sort(key=lambda x: x[1])\n",
        "        best = res[0][1]\n",
        "\n",
        "        # break after max_iter\n",
        "        if max_iter and iters >= max_iter:\n",
        "            return res[0], record\n",
        "        iters += 1\n",
        "        #print(iters)\n",
        "\n",
        "        # break after no_improv_break iterations with no improvement\n",
        "        print('...best so far:', best)\n",
        "\n",
        "        if best < prev_best - no_improve_thr:\n",
        "            no_improv = 0\n",
        "            prev_best = best\n",
        "        else:\n",
        "            no_improv += 1\n",
        "\n",
        "        if no_improv >= no_improv_break:\n",
        "            return res[0], record\n",
        "\n",
        "        # centroid\n",
        "        x0 = [0.] * dim\n",
        "        for tup in res[:-1]:\n",
        "            for i, c in enumerate(tup[0]):\n",
        "                x0[i] += c / (len(res)-1)\n",
        "\n",
        "        # reflection\n",
        "        xr = x0 + alpha*(x0 - res[-1][0])\n",
        "        rscore = f(xr,*args)\n",
        "        if res[0][1] <= rscore < res[-2][1]:\n",
        "            del res[-1]\n",
        "            res.append([xr, rscore])\n",
        "            record.append(copy.deepcopy(res))\n",
        "            continue\n",
        "\n",
        "        # expansion\n",
        "        if rscore < res[0][1]:\n",
        "            xe = x0 + gamma*(x0 - res[-1][0])\n",
        "            escore = f(xe,*args)\n",
        "            if escore < rscore:\n",
        "                del res[-1]\n",
        "                res.append([xe, escore])\n",
        "                record.append(copy.deepcopy(res))\n",
        "                continue\n",
        "            else:\n",
        "                del res[-1]\n",
        "                res.append([xr, rscore])\n",
        "                record.append(copy.deepcopy(res))\n",
        "                continue\n",
        "\n",
        "        # contraction\n",
        "        xc = x0 + rho*(x0 - res[-1][0])\n",
        "        cscore = f(xc,*args)\n",
        "        if cscore < res[-1][1]:\n",
        "            del res[-1]\n",
        "            res.append([xc, cscore])\n",
        "            record.append(copy.deepcopy(res))\n",
        "            continue\n",
        "\n",
        "        # reduction\n",
        "        x1 = res[0][0]\n",
        "        nres = []\n",
        "        for tup in res:\n",
        "            redx = x1 + sigma*(tup[0] - x1)\n",
        "            score = f(redx,*args)\n",
        "            nres.append([redx, score])\n",
        "        res = nres\n",
        "        record.append(copy.deepcopy(res))\n",
        "\n",
        "\n",
        "#if __name__ == \"__main__\":\n",
        "#    # test\n",
        "#    import math\n",
        "#    import numpy as np\n",
        "#\n",
        "#    def f(x):\n",
        "#        return math.sin(x[0]) * math.cos(x[1]) * (1. / (abs(x[2]) + 1))\n",
        "#\n",
        "#    print nelder_mead(f, np.array([0., 0., 0.]))"
      ],
      "metadata": {
        "id": "p_QtZx5Jakye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##part 1: preparations"
      ],
      "metadata": {
        "id": "NQ1FGYlzEmMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataset\n",
        "SEED = 2023\n",
        "#random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "N=1000\n",
        "X1,Y1=create_data_1(N)\n",
        "X1_train = X1[:N]\n",
        "Y1_train = Y1[:N]\n",
        "X1_infer = X1[N:]\n",
        "Y1_infer = Y1[N:]\n",
        "\n",
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 9999})'''))\n",
        "visualize_data(X1,Y1,\"dataset\")\n",
        "visualize_data(X1_train,Y1_train,\"dataset train\")\n",
        "visualize_data(X1_infer,Y1_infer,\"dataset infer\")"
      ],
      "metadata": {
        "id": "OOMovlFg13cx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# implement perceptron\n",
        "def MyPerceptron1(w,x):\n",
        "    y = None # edit here\n",
        "    return y\n",
        "\n",
        "# implement loss function\n",
        "def MyLossFunction(w,x,y,model):\n",
        "    return 0 # edit here"
      ],
      "metadata": {
        "id": "YgIG6vh79YFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##part 2: train"
      ],
      "metadata": {
        "id": "MYxRDd57xVom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# run Downhill Simplex Optimization (Nelderâ€“Mead method)\n",
        "res,record = nelder_mead(MyLossFunction, x_start = np.array([0.0,0.0]), args=(X1_train,Y1_train,MyPerceptron1) )"
      ],
      "metadata": {
        "id": "ZVDpBvKemdK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# in order to plot the optimization process with animation\n",
        "# save the values of weights at each iteration (together with losses)\n",
        "n_steps = len(record)\n",
        "record_w = np.zeros([n_steps,3,2],dtype=np.float32)\n",
        "record_l = np.zeros([n_steps,3],dtype=np.float32)\n",
        "for i in range(n_steps):\n",
        "    for j in range(3):\n",
        "        record_w[i,j,:] = record[i][j][0]\n",
        "        record_l[i,j]   = record[i][j][1]"
      ],
      "metadata": {
        "id": "KVDBBhCP1OAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print weights at each iteration\n",
        "print(record_w)"
      ],
      "metadata": {
        "id": "wIEX-UUhMNLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print losses at each iteration\n",
        "print(record_l)"
      ],
      "metadata": {
        "id": "BvuBRYesMRfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate loss values at each point in parameter space\n",
        "# https://matplotlib.org/stable/gallery/mplot3d/surface3d.html\n",
        "w0s = np.arange(-1.0, 7.0, 0.1) # modify this to see the minimum area with higher contrast during task 3\n",
        "w1s = np.arange(-1.0, 7.0, 0.1) # modify this to see the minimum area with higher contrast during task 3\n",
        "w0s, w1s = np.meshgrid(w0s, w1s)\n",
        "L = np.zeros_like(w0s)\n",
        "for i in range(len(w0s)):\n",
        "    for j in range(len(w1s)):\n",
        "        W = np.array([w0s[i,j],w1s[i,j]])\n",
        "        L[i,j] = MyLossFunction(W,X1_train,Y1_train,MyPerceptron1)"
      ],
      "metadata": {
        "id": "31Uad1TJ2_He"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the optimization process\n",
        "from matplotlib import rc\n",
        "rc('animation', html='jshtml')\n",
        "import IPython\n",
        "import matplotlib.animation as animation\n",
        "from matplotlib import cm\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "#surf = ax.plot_surface(w0s, w1s, L, cmap=cm.coolwarm,linewidth=0, antialiased=False)\n",
        "surf = ax.pcolormesh(w0s, w1s, L, cmap=cm.coolwarm,linewidth=0, antialiased=False)\n",
        "\n",
        "line1 = ax.plot([record_w[0,0,0], record_w[0,1,0]], [record_w[0,0,1], record_w[0,1,1]], color='k', linestyle='-', linewidth=1)[0]\n",
        "line2 = ax.plot([record_w[0,1,0], record_w[0,2,0]], [record_w[0,1,1], record_w[0,2,1]], color='k', linestyle='-', linewidth=1)[0]\n",
        "line3 = ax.plot([record_w[0,2,0], record_w[0,0,0]], [record_w[0,2,1], record_w[0,0,1]], color='k', linestyle='-', linewidth=1)[0]\n",
        "\n",
        "def update(frame):\n",
        "    line1.set_xdata([record_w[frame,0,0], record_w[frame,1,0]])\n",
        "    line1.set_ydata([record_w[frame,0,1], record_w[frame,1,1]])\n",
        "    line2.set_xdata([record_w[frame,1,0], record_w[frame,2,0]])\n",
        "    line2.set_ydata([record_w[frame,1,1], record_w[frame,2,1]])\n",
        "    line3.set_xdata([record_w[frame,2,0], record_w[frame,0,0]])\n",
        "    line3.set_ydata([record_w[frame,2,1], record_w[frame,0,1]])\n",
        "    return (line1, line2, line3)\n",
        "\n",
        "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
        "plt.xlabel('w0')\n",
        "plt.ylabel('w1')\n",
        "plt.title(\"loss\")\n",
        "plt.show()\n",
        "\n",
        "ani = animation.FuncAnimation(fig=fig, func=update, frames=n_steps, interval=30)\n",
        "ani\n"
      ],
      "metadata": {
        "id": "CfQiX_rV2_QY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## part 3: infer"
      ],
      "metadata": {
        "id": "5otwTiOw30I_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y1_infer_pred = MyPerceptron1(res[0],X1_infer)\n",
        "Y1_infer_pred[Y1_infer_pred<=0.5] = 0.0\n",
        "Y1_infer_pred[Y1_infer_pred> 0.5] = 1.0"
      ],
      "metadata": {
        "id": "Yv8kK2hDAQeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(Y1_infer,Y1_infer_pred)"
      ],
      "metadata": {
        "id": "kIqXSp0O2XsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_decision_boundary(X1_infer,Y1_infer_pred,res[0],MyPerceptron1)"
      ],
      "metadata": {
        "id": "UyE0v3pd2c5e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abeebyekeen/DLforBeginners/blob/main/overfitting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will delve into one of the most crucial aspects of training neural networks: understanding and addressing overfitting.\n",
        "\n",
        "# **What is Overfitting?**\n",
        "**Overfitting** is a common problem in training neural networks where developed models perform well not just on our training data but also on unseen data.\n",
        "\n",
        "In this section, we will see an example of overfitting problem and how we will address it."
      ],
      "metadata": {
        "id": "pipxHbuQx8qa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_jQkVFrWKJK"
      },
      "outputs": [],
      "source": [
        "# box 2.1\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_moons\n",
        "from sklearn.model_selection import train_test_split\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# box 2.2\n",
        "# 1. Generate  Dataset\n",
        "X, y = make_moons(n_samples=300, noise=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "X_train, X_val, y_train, y_val = map(torch.tensor, (X_train, X_val, y_train, y_val))\n",
        "y_train, y_val = y_train.float(), y_val.float()\n",
        "\n",
        "# Plot the scatter of the data\n",
        "import numpy as np\n",
        "x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
        "y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
        "h = 0.02\n",
        "\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                      np.arange(y_min, y_max, h))\n",
        "plt.scatter(X[y == 0][:, 0], X[y == 0][:, 1], color='blue', label='Class 0')\n",
        "plt.scatter(X[y == 1][:, 0], X[y == 1][:, 1], color='red', label='Class 1')\n",
        "\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "rmWE-YBmWZTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# box 2.3\n",
        "# 2. Create a Deep Neural Network\n",
        "class DeepNet(nn.Module):\n",
        "    def __init__(self, dropout_rate=0.0):\n",
        "        super(DeepNet, self).__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(2, 64),\n",
        "            nn.ReLU(), #Uncomment  ('ctrl'+'/') this to have non-linear classifier\n",
        "            nn.Dropout(dropout_rate), #Please ignore this layer if dropout_rate = 0\n",
        "            nn.Linear(64, 64),\n",
        "            nn.ReLU(), #Uncomment  ('ctrl'+'/') this to have non-linear classifier\n",
        "            nn.Dropout(dropout_rate), #Please ignore this layer if dropout_rate = 0\n",
        "            nn.Linear(64, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "# Summarize the model and its output\n",
        "from torchsummary import summary\n",
        "model = DeepNet()\n",
        "summary(model, (1,2))"
      ],
      "metadata": {
        "id": "LbqX4a2QRWIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# box 2.4\n",
        "model_without_reg = DeepNet()\n",
        "\n",
        "# Training Settings\n",
        "optimizer = optim.Adam(model_without_reg.parameters(), lr=0.01)\n",
        "loss_fn = nn.BCELoss()\n",
        "\n",
        "# 3. Train the Model (Without Regularization) and Observe Overfitting\n",
        "num_epochs = 500\n",
        "train_losses, val_losses = [], []\n",
        "saved_models = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Train\n",
        "    model_without_reg.train()\n",
        "    optimizer.zero_grad()\n",
        "    predictions = model_without_reg(X_train.float()).squeeze()\n",
        "    loss = loss_fn(predictions, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    #save model at epoch 0, 100, 200, 300, 400\n",
        "    if epoch % 100 == 0:\n",
        "        model_state = copy.deepcopy(model_without_reg).state_dict()\n",
        "        saved_models.append(model_state)\n",
        "    # Validate\n",
        "    model_without_reg.eval()\n",
        "    with torch.no_grad():\n",
        "        val_predictions = model_without_reg(X_val.float()).squeeze()\n",
        "        val_loss = loss_fn(val_predictions, y_val)\n",
        "        val_losses.append(val_loss.item())\n",
        "\n",
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.title(\"Without Regularization\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o_5bOX29Rbvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's plot the decision boundary to understand the overfitting problem"
      ],
      "metadata": {
        "id": "jaLwRweu64Fg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# box 2.5\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_moons\n",
        "\n",
        "\n",
        "# Function to plot the decision boundary\n",
        "def plot_decision_boundary(model, X, y):\n",
        "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
        "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
        "    h = 0.02\n",
        "\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                         np.arange(y_min, y_max, h))\n",
        "\n",
        "    # Predict the function value for the entire grid\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        Z = model(torch.tensor(np.c_[xx.ravel(), yy.ravel()]).float()).squeeze()\n",
        "        Z = Z.reshape(xx.shape)\n",
        "\n",
        "    # Plot the contour with only two regions\n",
        "    plt.contourf(xx, yy, Z.detach().numpy(), levels=[0, 0.5, 1], cmap=plt.cm.Spectral, alpha=0.8)\n",
        "    plt.scatter(X[y == 0][:, 0], X[y == 0][:, 1], color='blue', label='Class 0')\n",
        "    plt.scatter(X[y == 1][:, 0], X[y == 1][:, 1], color='red', label='Class 1')\n",
        "\n",
        "    plt.xlabel('Feature 1')\n",
        "    plt.ylabel('Feature 2')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "plt.title('Decision Boundary - Training')\n",
        "plot_decision_boundary(model_without_reg, X_train, y_train)\n",
        "\n",
        "\n",
        "plt.title('Decision Boundary - Validation')\n",
        "plot_decision_boundary(model_without_reg, X_val, y_val)"
      ],
      "metadata": {
        "id": "iEcg-F1Z6moq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's observe the boundary decision and magnitude of weight over epochs"
      ],
      "metadata": {
        "id": "z8DMwXO_VJQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# box 2.6\n",
        "for i in range(len(saved_models)):\n",
        "  model_to_load = DeepNet()\n",
        "\n",
        "  model_state = saved_models[i]\n",
        "  # Load the saved model state into the model instance\n",
        "  model_to_load.load_state_dict(model_state)\n",
        "  max_weight_magnitude = max(torch.max(torch.abs(param)).item() for param in model_to_load.parameters() if param.requires_grad)\n",
        "  plt.title(f'Decision Boundary - Validation - epoch  {i*100} - max weight magnitude {max_weight_magnitude}')\n",
        "  plot_decision_boundary(model_to_load, X_val, y_val)"
      ],
      "metadata": {
        "id": "-J780Qs7TNF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Combat overfitting**\n",
        "Here are a few methods used to combat overfitting:\n",
        "\n",
        "* Data Augmentation: Increasing the size and diversity of the training dataset\n",
        "\n",
        "* **Regularization**: Regularization techniques add a penalty term to the loss function to discourage complex models.\n",
        "\n",
        "* **Dropout**: A technique used in neural networks where randomly selected neurons are ignored during training.\n",
        "\n",
        "* Early Stopping: Involves stopping the training process before the model fully fits the training data.\n",
        "\n",
        "* Cross-Validation: Involves dividing the dataset into subsets and using them in rotating combinations to train and validate the model.\n",
        "\n",
        "Today, we will try to use regularization and dropout method to address the overfitting problem.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IOSgHpRO2EPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# box 2.7\n",
        "# 4. Apply Regularization (L2 + Dropout) and Observe Reduced Overfitting\n",
        "model_with_reg = DeepNet(dropout_rate=0.0)  # Add Dropout\n",
        "optimizer = optim.Adam(model_with_reg.parameters(), lr=0.01, weight_decay=0.01)  # L2 regularization with weight decay\n",
        "train_losses_reg, val_losses_reg = [], []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Train\n",
        "    model_with_reg.train()\n",
        "    optimizer.zero_grad()\n",
        "    predictions = model_with_reg(X_train.float()).squeeze()\n",
        "    loss = loss_fn(predictions, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    train_losses_reg.append(loss.item())\n",
        "\n",
        "    # Validate\n",
        "    model_with_reg.eval()\n",
        "    with torch.no_grad():\n",
        "        val_predictions = model_with_reg(X_val.float()).squeeze()\n",
        "        val_loss = loss_fn(val_predictions, y_val)\n",
        "        val_losses_reg.append(val_loss.item())\n",
        "\n",
        "plt.plot(train_losses_reg, label='Training Loss with Regularization')\n",
        "plt.plot(val_losses_reg, label='Validation Loss with Regularization')\n",
        "plt.legend()\n",
        "plt.title(\"With Regularization\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "iOxfrtYYReXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will plot the decision boundary to observe how regularization helps to remove overfitting"
      ],
      "metadata": {
        "id": "vEC9I0cr52oP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# box 2.8\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_moons\n",
        "\n",
        "\n",
        "# Function to plot the decision boundary\n",
        "def plot_decision_boundary(model, X, y):\n",
        "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
        "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
        "    h = 0.02\n",
        "\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                         np.arange(y_min, y_max, h))\n",
        "\n",
        "    # Predict the function value for the entire grid\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        Z = model(torch.tensor(np.c_[xx.ravel(), yy.ravel()]).float()).squeeze()\n",
        "        Z = Z.reshape(xx.shape)\n",
        "\n",
        "    # Plot the contour with only two regions\n",
        "    plt.contourf(xx, yy, Z.detach().numpy(), levels=[0, 0.5, 1], cmap=plt.cm.Spectral, alpha=0.8)\n",
        "    plt.scatter(X[y == 0][:, 0], X[y == 0][:, 1], color='blue', label='Class 0')\n",
        "    plt.scatter(X[y == 1][:, 0], X[y == 1][:, 1], color='red', label='Class 1')\n",
        "\n",
        "    plt.xlabel('Feature 1')\n",
        "    plt.ylabel('Feature 2')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "plt.title('Decision Boundary Without Regularization - Training')\n",
        "plot_decision_boundary(model_without_reg, X_train, y_train)\n",
        "\n",
        "\n",
        "plt.title('Decision Boundary Without Regularization - Validation')\n",
        "plot_decision_boundary(model_without_reg, X_val, y_val)\n",
        "\n",
        "\n",
        "plt.title('Decision Boundary With Regularization - Training')\n",
        "plot_decision_boundary(model_with_reg, X_train, y_train)\n",
        "\n",
        "plt.title('Decision Boundary With Regularization - Validation')\n",
        "plot_decision_boundary(model_with_reg, X_val, y_val)\n"
      ],
      "metadata": {
        "id": "qkeJ_a4LRi7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# box 2.9\n",
        "max_weight_magnitude = max(torch.max(torch.abs(param)).item() for param in model_without_reg.parameters() if param.requires_grad)\n",
        "print('maximum magnitude of parameters (weights) in model without regularization is ', max_weight_magnitude)\n",
        "print('training loss without regularization: ', train_losses[-1])\n",
        "print('testing/validation loss without regularization: ', val_losses[-1])\n",
        "max_weight_magnitude = max(torch.max(torch.abs(param)).item() for param in model_with_reg.parameters() if param.requires_grad)\n",
        "print('maximum magnitude of parameters (weights) in model with regularization is ', max_weight_magnitude)\n",
        "print('training loss with regularization: ', train_losses_reg[-1])\n",
        "print('testing/validation loss with regularization: ', val_losses_reg[-1])\n"
      ],
      "metadata": {
        "id": "OYh2o5zYSFOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CqGRvmn0PDWf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}